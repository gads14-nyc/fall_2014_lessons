{
 "metadata": {
  "name": "",
  "signature": "sha256:5cfc9edf5942392b8ddc7b766d0e12be7f37ccca8e62af7af62cccb77facfdb4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('https://raw.githubusercontent.com/TeachingDataScience/data-science-course/forstudentviewing/12_Naive_Bayes/twitter_training/sts_gold_tweet.csv',';')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "(2034, 3)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df['polarity']==4].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "(632, 3)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df['polarity']==0].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "(1402, 3)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data is \"unbalanced\" in the sense that the number of 0 polarity tweets outnumbers the 4 polarity tweets. This represents different priors. Reading about the Naive Baye's model indicates that this is taken care of. The model measures the priors."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>id</th>\n",
        "      <th>polarity</th>\n",
        "      <th>tweet</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1467933112</td>\n",
        "      <td> 0</td>\n",
        "      <td> the angel is going to miss the athlete this we...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 2323395086</td>\n",
        "      <td> 0</td>\n",
        "      <td> It looks as though Shaq is getting traded to C...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1467968979</td>\n",
        "      <td> 0</td>\n",
        "      <td>    @clarianne APRIL 9TH ISN'T COMING SOON ENOUGH </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1990283756</td>\n",
        "      <td> 0</td>\n",
        "      <td> drinking a McDonalds coffee and not understand...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 1988884918</td>\n",
        "      <td> 0</td>\n",
        "      <td> So dissapointed Taylor Swift doesnt have a Twi...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "           id  polarity                                              tweet\n",
        "0  1467933112         0  the angel is going to miss the athlete this we...\n",
        "1  2323395086         0  It looks as though Shaq is getting traded to C...\n",
        "2  1467968979         0     @clarianne APRIL 9TH ISN'T COMING SOON ENOUGH \n",
        "3  1990283756         0  drinking a McDonalds coffee and not understand...\n",
        "4  1988884918         0  So dissapointed Taylor Swift doesnt have a Twi..."
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df['polarity']==4].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>id</th>\n",
        "      <th>polarity</th>\n",
        "      <th>tweet</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>77</th>\n",
        "      <td> 1680347120</td>\n",
        "      <td> 4</td>\n",
        "      <td> @ mcdonalds with my litto sis aka cuzin lol cr...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>78</th>\n",
        "      <td> 1835259469</td>\n",
        "      <td> 4</td>\n",
        "      <td> @AnnaSaccone Love your new cards!   I would de...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>79</th>\n",
        "      <td> 1983068285</td>\n",
        "      <td> 4</td>\n",
        "      <td> @supricky06 that was one of the most enjoyable...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>80</th>\n",
        "      <td> 1559842363</td>\n",
        "      <td> 4</td>\n",
        "      <td> Dallas vegas goodness  http://twitpic.com/3lzt...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>81</th>\n",
        "      <td> 1999078293</td>\n",
        "      <td> 4</td>\n",
        "      <td> @JBsFanArgentina Hey I luv this pic!!! was ama...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "            id  polarity                                              tweet\n",
        "77  1680347120         4  @ mcdonalds with my litto sis aka cuzin lol cr...\n",
        "78  1835259469         4  @AnnaSaccone Love your new cards!   I would de...\n",
        "79  1983068285         4  @supricky06 that was one of the most enjoyable...\n",
        "80  1559842363         4  Dallas vegas goodness  http://twitpic.com/3lzt...\n",
        "81  1999078293         4  @JBsFanArgentina Hey I luv this pic!!! was ama..."
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Consider other features, such as the percentage capitalization of the tweet."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['per_cap'] = df.tweet.apply(lambda x: sum([float(x[i] == x.upper()[i]) for i in range(len(x))])/len(x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['tweet'][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "'the angel is going to miss the athlete this weekend '"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The above implementation treats blank spaces bewteen words as capitalized.Modify this by first collapsing the word string \n",
      "by removing all spaces."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['per_cap'][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "0.19230769230769232"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b = lambda x: sum([float(x[i] == x.upper()[i]) for i in range(len(x))])/len(x)\n",
      "b(df['tweet'][0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "0.19230769230769232"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['tweetnospaces'] = df.tweet.apply(lambda x: x.replace(' ',''))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print df['tweet'][0]\n",
      "print df['tweetnospaces'][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "the angel is going to miss the athlete this weekend \n",
        "theangelisgoingtomisstheathletethisweekend\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['per_cap_nosp'] = df.tweetnospaces.apply(lambda x: sum([float(x[i] == x.upper()[i]) for i in range(len(x))])/len(x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b = lambda x: sum([float(x[i] == x.upper()[i]) for i in range(len(x))])/len(x)\n",
      "print b(df['tweetnospaces'][0])\n",
      "print b(\"THISISATEST\")\n",
      "print b(\"AndhowABOUTTHIS!\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0\n",
        "1.0\n",
        "0.6875\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Also create all lower case tweets - since the capitalization is now treated as a separate feature. NB: I noted later that\n",
      "Count Vectorizer already does this - i.e. there is a default setting that converts all to lowercase."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['tweetlower'] = df.tweet.apply(lambda x: x.lower())\n",
      "df['tweetlower'][1:2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "1    it looks as though shaq is getting traded to c...\n",
        "Name: tweetlower, dtype: object"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Consider also the benefit (or otherwise) of removing the Twitter \"at\" symbol and name. Use a regular expression to achieve this."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['tweet'][294]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "'@spicebugsmom A few more for you to follow: @aims7 @alirushton @dillyh @Oprah @timescolonist @JohnCleese ...Welcome to Twitter mums '"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#Elegant use of regex.\n",
      "\n",
      "pattern = r'@[A-Za-z0-9]*'\n",
      "regex = re.compile(pattern, flags=re.IGNORECASE)\n",
      "for i in range(290,300):\n",
      "    print i, regex.findall(df['tweet'][i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "290 []\n",
        "291 []\n",
        "292 []\n",
        "293 []\n",
        "294 ['@spicebugsmom', '@aims7', '@alirushton', '@dillyh', '@Oprah', '@timescolonist', '@JohnCleese']\n",
        "295 []\n",
        "296 []\n",
        "297 ['@mishacollins', '@oprah']\n",
        "298 ['@DaRealSunisaKim']\n",
        "299 []\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print regex.split(df['tweet'][294])[1]\n",
      "print regex.split(df['tweet'][294])[7]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " A few more for you to follow: \n",
        " ...Welcome to Twitter mums \n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['tweetrhtag'] = df.tweet.apply(lambda x: regex.sub('',x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['tweetrhtag'][294]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "' A few more for you to follow:       ...Welcome to Twitter mums '"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>id</th>\n",
        "      <th>polarity</th>\n",
        "      <th>tweet</th>\n",
        "      <th>per_cap</th>\n",
        "      <th>tweetnospaces</th>\n",
        "      <th>per_cap_nosp</th>\n",
        "      <th>tweetlower</th>\n",
        "      <th>tweetrhtag</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1467933112</td>\n",
        "      <td> 0</td>\n",
        "      <td> the angel is going to miss the athlete this we...</td>\n",
        "      <td> 0.192308</td>\n",
        "      <td>        theangelisgoingtomisstheathletethisweekend</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> the angel is going to miss the athlete this we...</td>\n",
        "      <td> the angel is going to miss the athlete this we...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 2323395086</td>\n",
        "      <td> 0</td>\n",
        "      <td> It looks as though Shaq is getting traded to C...</td>\n",
        "      <td> 0.325397</td>\n",
        "      <td> ItlooksasthoughShaqisgettingtradedtoClevelandt...</td>\n",
        "      <td> 0.158416</td>\n",
        "      <td> it looks as though shaq is getting traded to c...</td>\n",
        "      <td> It looks as though Shaq is getting traded to C...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1467968979</td>\n",
        "      <td> 0</td>\n",
        "      <td>    @clarianne APRIL 9TH ISN'T COMING SOON ENOUGH </td>\n",
        "      <td> 0.804348</td>\n",
        "      <td>           @clarianneAPRIL9THISN'TCOMINGSOONENOUGH</td>\n",
        "      <td> 0.769231</td>\n",
        "      <td>    @clarianne april 9th isn't coming soon enough </td>\n",
        "      <td>               APRIL 9TH ISN'T COMING SOON ENOUGH </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1990283756</td>\n",
        "      <td> 0</td>\n",
        "      <td> drinking a McDonalds coffee and not understand...</td>\n",
        "      <td> 0.190000</td>\n",
        "      <td> drinkingaMcDonaldscoffeeandnotunderstandingwhy...</td>\n",
        "      <td> 0.035714</td>\n",
        "      <td> drinking a mcdonalds coffee and not understand...</td>\n",
        "      <td> drinking a McDonalds coffee and not understand...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 1988884918</td>\n",
        "      <td> 0</td>\n",
        "      <td> So dissapointed Taylor Swift doesnt have a Twi...</td>\n",
        "      <td> 0.235294</td>\n",
        "      <td>       SodissapointedTaylorSwiftdoesnthaveaTwitter</td>\n",
        "      <td> 0.093023</td>\n",
        "      <td> so dissapointed taylor swift doesnt have a twi...</td>\n",
        "      <td> So dissapointed Taylor Swift doesnt have a Twi...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "           id  polarity                                              tweet  \\\n",
        "0  1467933112         0  the angel is going to miss the athlete this we...   \n",
        "1  2323395086         0  It looks as though Shaq is getting traded to C...   \n",
        "2  1467968979         0     @clarianne APRIL 9TH ISN'T COMING SOON ENOUGH    \n",
        "3  1990283756         0  drinking a McDonalds coffee and not understand...   \n",
        "4  1988884918         0  So dissapointed Taylor Swift doesnt have a Twi...   \n",
        "\n",
        "    per_cap                                      tweetnospaces  per_cap_nosp  \\\n",
        "0  0.192308         theangelisgoingtomisstheathletethisweekend      0.000000   \n",
        "1  0.325397  ItlooksasthoughShaqisgettingtradedtoClevelandt...      0.158416   \n",
        "2  0.804348            @clarianneAPRIL9THISN'TCOMINGSOONENOUGH      0.769231   \n",
        "3  0.190000  drinkingaMcDonaldscoffeeandnotunderstandingwhy...      0.035714   \n",
        "4  0.235294        SodissapointedTaylorSwiftdoesnthaveaTwitter      0.093023   \n",
        "\n",
        "                                          tweetlower  \\\n",
        "0  the angel is going to miss the athlete this we...   \n",
        "1  it looks as though shaq is getting traded to c...   \n",
        "2     @clarianne april 9th isn't coming soon enough    \n",
        "3  drinking a mcdonalds coffee and not understand...   \n",
        "4  so dissapointed taylor swift doesnt have a twi...   \n",
        "\n",
        "                                          tweetrhtag  \n",
        "0  the angel is going to miss the athlete this we...  \n",
        "1  It looks as though Shaq is getting traded to C...  \n",
        "2                APRIL 9TH ISN'T COMING SOON ENOUGH   \n",
        "3  drinking a McDonalds coffee and not understand...  \n",
        "4  So dissapointed Taylor Swift doesnt have a Twi...  "
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df['polarity']==4].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>id</th>\n",
        "      <th>polarity</th>\n",
        "      <th>tweet</th>\n",
        "      <th>per_cap</th>\n",
        "      <th>tweetnospaces</th>\n",
        "      <th>per_cap_nosp</th>\n",
        "      <th>tweetlower</th>\n",
        "      <th>tweetrhtag</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>77</th>\n",
        "      <td> 1680347120</td>\n",
        "      <td> 4</td>\n",
        "      <td> @ mcdonalds with my litto sis aka cuzin lol cr...</td>\n",
        "      <td> 0.200000</td>\n",
        "      <td>     @mcdonaldswithmylittosisakacuzinlolcristyyyyy</td>\n",
        "      <td> 0.022222</td>\n",
        "      <td> @ mcdonalds with my litto sis aka cuzin lol cr...</td>\n",
        "      <td>  mcdonalds with my litto sis aka cuzin lol cri...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>78</th>\n",
        "      <td> 1835259469</td>\n",
        "      <td> 4</td>\n",
        "      <td> @AnnaSaccone Love your new cards!   I would de...</td>\n",
        "      <td> 0.313433</td>\n",
        "      <td> @AnnaSacconeLoveyournewcards!Iwoulddefinitelyh...</td>\n",
        "      <td> 0.163636</td>\n",
        "      <td> @annasaccone love your new cards!   i would de...</td>\n",
        "      <td>  Love your new cards!   I would definitely hir...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>79</th>\n",
        "      <td> 1983068285</td>\n",
        "      <td> 4</td>\n",
        "      <td> @supricky06 that was one of the most enjoyable...</td>\n",
        "      <td> 0.297297</td>\n",
        "      <td> @supricky06thatwasoneofthemostenjoyableexperie...</td>\n",
        "      <td> 0.178947</td>\n",
        "      <td> @supricky06 that was one of the most enjoyable...</td>\n",
        "      <td>  that was one of the most enjoyable experience...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>80</th>\n",
        "      <td> 1559842363</td>\n",
        "      <td> 4</td>\n",
        "      <td> Dallas vegas goodness  http://twitpic.com/3lzt...</td>\n",
        "      <td> 0.306667</td>\n",
        "      <td> Dallasvegasgoodnesshttp://twitpic.com/3lzt1Onm...</td>\n",
        "      <td> 0.174603</td>\n",
        "      <td> dallas vegas goodness  http://twitpic.com/3lzt...</td>\n",
        "      <td> Dallas vegas goodness  http://twitpic.com/3lzt...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>81</th>\n",
        "      <td> 1999078293</td>\n",
        "      <td> 4</td>\n",
        "      <td> @JBsFanArgentina Hey I luv this pic!!! was ama...</td>\n",
        "      <td> 0.472527</td>\n",
        "      <td> @JBsFanArgentinaHeyIluvthispic!!!wasamazingoft...</td>\n",
        "      <td> 0.351351</td>\n",
        "      <td> @jbsfanargentina hey i luv this pic!!! was ama...</td>\n",
        "      <td>  Hey I luv this pic!!! was amazing of the last...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "            id  polarity                                              tweet  \\\n",
        "77  1680347120         4  @ mcdonalds with my litto sis aka cuzin lol cr...   \n",
        "78  1835259469         4  @AnnaSaccone Love your new cards!   I would de...   \n",
        "79  1983068285         4  @supricky06 that was one of the most enjoyable...   \n",
        "80  1559842363         4  Dallas vegas goodness  http://twitpic.com/3lzt...   \n",
        "81  1999078293         4  @JBsFanArgentina Hey I luv this pic!!! was ama...   \n",
        "\n",
        "     per_cap                                      tweetnospaces  per_cap_nosp  \\\n",
        "77  0.200000      @mcdonaldswithmylittosisakacuzinlolcristyyyyy      0.022222   \n",
        "78  0.313433  @AnnaSacconeLoveyournewcards!Iwoulddefinitelyh...      0.163636   \n",
        "79  0.297297  @supricky06thatwasoneofthemostenjoyableexperie...      0.178947   \n",
        "80  0.306667  Dallasvegasgoodnesshttp://twitpic.com/3lzt1Onm...      0.174603   \n",
        "81  0.472527  @JBsFanArgentinaHeyIluvthispic!!!wasamazingoft...      0.351351   \n",
        "\n",
        "                                           tweetlower  \\\n",
        "77  @ mcdonalds with my litto sis aka cuzin lol cr...   \n",
        "78  @annasaccone love your new cards!   i would de...   \n",
        "79  @supricky06 that was one of the most enjoyable...   \n",
        "80  dallas vegas goodness  http://twitpic.com/3lzt...   \n",
        "81  @jbsfanargentina hey i luv this pic!!! was ama...   \n",
        "\n",
        "                                           tweetrhtag  \n",
        "77   mcdonalds with my litto sis aka cuzin lol cri...  \n",
        "78   Love your new cards!   I would definitely hir...  \n",
        "79   that was one of the most enjoyable experience...  \n",
        "80  Dallas vegas goodness  http://twitpic.com/3lzt...  \n",
        "81   Hey I luv this pic!!! was amazing of the last...  "
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.naive_bayes import BernoulliNB"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Start with a Naive Bayes model using the Count Vectorizer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['tweet'][1:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "1    It looks as though Shaq is getting traded to C...\n",
        "2       @clarianne APRIL 9TH ISN'T COMING SOON ENOUGH \n",
        "3    drinking a McDonalds coffee and not understand...\n",
        "4    So dissapointed Taylor Swift doesnt have a Twi...\n",
        "Name: tweet, dtype: object"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = CountVectorizer(ngram_range=(1,2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer.fit(df['tweet'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "CountVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
        "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
        "        tokenizer=None, vocabulary=None)"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ll=vectorizer.get_feature_names()\n",
      "for i in range(0,10):\n",
      "    print ll[i]\n",
      "len(ll)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "00\n",
        "00 am\n",
        "00 m33\n",
        "000\n",
        "000 at\n",
        "000 followers\n",
        "000gbp\n",
        "000gbp for\n",
        "00am\n",
        "00am little\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "24410"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP: The commendted function caused memory errors.  Going from a sparse matrix memory storage to \n",
      "#a full matrix fills in all the spaces with zeros.\n",
      "\n",
      "X = vectorizer.transform(df['tweet'])\n",
      "#x_back = X.toarray()\n",
      "#x_back.shape\n",
      "#print x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The sparse array, and indeed the one that is not sparse (x_back above) contains the information required to relate the generated ngrams back to the original tweet, based on the tweet's row number."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y = (df['polarity'] == 0).astype(np.int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#Using single brackets converts Y to a seris\n",
      "type(Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "pandas.core.series.Series"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Split the test set into two halves, rather than doing n-fold cross validation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#In your code you had a variable named X_back here, but the sparse matrix works and is much\n",
      "#faster"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xtrain, xtest, ytrain, ytest = train_test_split(X,Y, test_size=0.5, random_state=41)\n",
      "ytest[1:10]\n",
      "print xtrain.shape\n",
      "print xtest.shape\n",
      "print ytrain.shape\n",
      "print ytest.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1017, 24410)\n",
        "(1017, 24410)\n",
        "(1017,)\n",
        "(1017,)\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def accuracy_report(_clf, xtrain,ytrain,xtest, ytest):\n",
      "    print \"Accuracy: %0.2f%%\" % (100 * _clf.score(xtest, ytest))\n",
      "\n",
      "    #Print the accuracy on the test and training dataset\n",
      "    training_accuracy = _clf.score(xtrain, ytrain)\n",
      "    test_accuracy = _clf.score(xtest, ytest)\n",
      "\n",
      "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"multinomial\"\n",
      "clf_mn = MultinomialNB().fit(xtrain, ytrain)\n",
      "accuracy_report(clf_mn, xtrain, ytrain, xtest, ytest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "multinomial\n",
        "Accuracy: 82.99%\n",
        "Accuracy on training data: 0.99\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.crosstab(Y, clf_mn.predict(X), rownames=[\"Actual\"], colnames=[\"Predicted\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th>Predicted</th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Actual</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 500</td>\n",
        "      <td>  132</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>  49</td>\n",
        "      <td> 1353</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "Predicted    0     1\n",
        "Actual              \n",
        "0          500   132\n",
        "1           49  1353"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"bernoulli\"\n",
      "clf_b = BernoulliNB().fit(xtrain, ytrain)\n",
      "accuracy_report(clf_b, xtrain, ytrain, xtest, ytest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "bernoulli\n",
        "Accuracy: 69.22%\n",
        "Accuracy on training data: 0.73\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#Replaced x_back with X and it ran in seconds vs. a minute\n",
      "pd.crosstab(Y, clf_b.predict(X), rownames=[\"Actual\"], colnames=[\"Predicted\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th>Predicted</th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Actual</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 40</td>\n",
        "      <td>  592</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>  0</td>\n",
        "      <td> 1402</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "Predicted   0     1\n",
        "Actual             \n",
        "0          40   592\n",
        "1           0  1402"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def AnalyzeTweet(testtweet, _clf):\n",
      "    print \"\\\"\"  + testtweet + \"\\\" is judged by clasifier to be...\"\n",
      "    testtweet = vectorizer.transform([testtweet])\n",
      "\n",
      "    if (_clf.predict(testtweet)[0] == 0):\n",
      "        print \"... Positive Tweet.\"\n",
      "    else:\n",
      "        print \"... Negative Tweet.\"\n",
      "    return(_clf.predict(testtweet)[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print AnalyzeTweet(\"have a good day\", clf_mn)\n",
      "print AnalyzeTweet(\"this is fantastic\", clf_mn)\n",
      "print AnalyzeTweet(\"congrats on the new job\", clf_mn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"have a good day\" is judged by clasifier to be...\n",
        "... Negative Tweet.\n",
        "1\n",
        "\"this is fantastic\" is judged by clasifier to be...\n",
        "... Positive Tweet.\n",
        "0\n",
        "\"congrats on the new job\" is judged by clasifier to be...\n",
        "... Positive Tweet.\n",
        "0\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print AnalyzeTweet(\"what a pain that was\", clf_mn)\n",
      "print AnalyzeTweet(\"back luck about the interveiw\", clf_mn)\n",
      "print AnalyzeTweet(\"hopefully next time\", clf_mn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"what a pain that was\" is judged by clasifier to be...\n",
        "... Negative Tweet.\n",
        "1\n",
        "\"back luck about the interveiw\" is judged by clasifier to be...\n",
        "... Negative Tweet.\n",
        "1\n",
        "\"hopefully next time\" is judged by clasifier to be...\n",
        "... Negative Tweet.\n",
        "1\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Multinomial Naive Bayes has the better accuracy of the two models above."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Explore the TF-IDF Vectorizer to see if weighting ngrams according to their frequency helps the classification model. I \n",
      "suspect this might work better in longer form textual contexts such as email."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Initially do a little exploration of how this works."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tf={'Words':[\"The Learning is\", \"The Python is\", \"The one crazy person\"]}\n",
      "tf = pd.DataFrame(tf)\n",
      "tf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Words</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>      The Learning is</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>        The Python is</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> The one crazy person</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "                  Words\n",
        "0       The Learning is\n",
        "1         The Python is\n",
        "2  The one crazy person"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testTFV = TfidfVectorizer(ngram_range=(1,2))\n",
      "testTFV.fit(tf['Words'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "TfidfVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 2), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
        "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
        "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
        "        vocabulary=None)"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testTFV.get_feature_names()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "[u'crazy',\n",
        " u'crazy person',\n",
        " u'is',\n",
        " u'learning',\n",
        " u'learning is',\n",
        " u'one',\n",
        " u'one crazy',\n",
        " u'person',\n",
        " u'python',\n",
        " u'python is',\n",
        " u'the',\n",
        " u'the learning',\n",
        " u'the one',\n",
        " u'the python']"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testx = testTFV.transform(tf['Words'])\n",
      "#testxa = testx.toarray()\n",
      "testxa=testx\n",
      "testxa"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "<3x14 sparse matrix of type '<type 'numpy.float64'>'\n",
        "\twith 17 stored elements in Compressed Sparse Row format>"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizerTF = TfidfVectorizer(ngram_range=(1,2))\n",
      "vectorizerTF.fit(df['tweet'])\n",
      "XTF = vectorizerTF.transform(df['tweet'])\n",
      "#x_backTF = XTF.toarray() #JP: This line could cause problems by using too much memory\n",
      "x_backTF=XTF\n",
      "x_backTF.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "(2034, 24410)"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#Mark!  Sparse matrices exist for a reason!  Use them!\n",
      "\n",
      "#x_backTF "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Still a very sparse array"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "YTF = (df['polarity'] == 0).values.astype(np.int)\n",
      "xtrainTF, xtestTF, ytrainTF, ytestTF = train_test_split(x_backTF,YTF, test_size=0.5, random_state=41)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"multinomial\"\n",
      "clf_mn_tf = MultinomialNB().fit(xtrainTF, ytrainTF)\n",
      "accuracy_report(clf_mn_tf, xtrainTF, ytrainTF, xtestTF, ytestTF)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "multinomial\n",
        "Accuracy: 69.42%\n",
        "Accuracy on training data: 0.84\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "No hugely impressive. It significantly worsened the classification performance! Clearly weighting ngrams is not helpful in classification of tweets - well not in this instance anyway.\n",
      "Try adding the percentage capitalized column to the data.\n",
      "In terms of adding this feature all I have done is to add a column to the data matrix (array). \n",
      "This should, in theory, work."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#x_backTF_2 = np.zeros((2034, 24411))\n",
      "#print x_backTF_2.shape\n",
      "#x_backTF_2[:,:-1] = x_backTF\n",
      "#x_backTF_2[:,:-1] = x_back\n",
      "#x_backTF_2[:,24410]=df['per_cap_nosp'].values\n",
      "#x_backTF_2[1,:] #JP: memory error\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#You're approach is spot on: get concatenated sparse matrix by first converting them both\n",
      "#to dense matrices and then concatenating.  Alternatively, it's possible to concatenate two\n",
      "#sparse matrices directly using hstack from the scipy.sparse library.\n",
      "\n",
      "per_cap = df[['per_cap_nosp']].to_sparse() #note the two brackets. hstack would throw a mismatched\n",
      "#dimension error if we did only one bracket (since the output would be a sparse series)\n",
      "print type(per_cap)\n",
      "from scipy.sparse import hstack\n",
      "X2 = hstack([X,per_cap])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.sparse.frame.SparseDataFrame'>\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP:\n",
      "#for ease I used X2\n",
      "x_backTF_2 = X2\n",
      "#\n",
      "#\n",
      "\n",
      "YTF_2 = (df['polarity'] == 0).values.astype(np.int)\n",
      "\n",
      "xtrainTF_2, xtestTF_2, ytrainTF_2, ytestTF_2 = train_test_split(x_backTF_2,YTF_2, test_size=0.5, random_state=41)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"multinomial\"\n",
      "clf_mn_tf_2 = MultinomialNB().fit(xtrainTF_2, ytrainTF_2)\n",
      "accuracy_report(clf_mn_tf_2, xtrainTF_2, ytrainTF_2, xtestTF_2, ytestTF_2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "multinomial\n",
        "Accuracy: 82.99%\n",
        "Accuracy on training data: 0.99\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This certainly improved the classification performance!\n",
      "Let's return to the simple CountVectorizer.\n",
      "Try the Count Vectorizer using ngrams formed from lowercase tweets that have had their hashtags removed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer4 = CountVectorizer(ngram_range=(1,2), lowercase=True)\n",
      "vectorizer4.fit(df['tweetrhtag'])\n",
      "X4 = vectorizer4.transform(df['tweetrhtag'])\n",
      "#x4_back = X4.toarray() #JP: memory error\n",
      "x4_back = X4\n",
      "print x4_back.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(2034, 23047)\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y4 = (df['polarity'] == 0).values.astype(np.int)\n",
      "xtrain4, xtest4, ytrain4, ytest4 = train_test_split(x4_back,Y4, test_size=0.5, random_state=41)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"multinomial\"\n",
      "clf_mn_4 = MultinomialNB().fit(xtrain4, ytrain4)\n",
      "accuracy_report(clf_mn_4, xtrain4, ytrain4, xtest4, ytest4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "multinomial\n",
        "Accuracy: 82.60%\n",
        "Accuracy on training data: 0.99\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Again add an extra column to the array to add the percentage capitalized column"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#Again here's the shorthand way to do this:\n",
      "x4_back_2 = hstack([x4_back,per_cap])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x4_back_2 = np.zeros((2034, len(x4_back[0])+1))\n",
      "print x4_back_2.shape\n",
      "#x_backTF_2[:,:-1] = x_backTF\n",
      "x4_back_2[:,:-1] = x4_back\n",
      "x4_back_2[:,len(x4_back[0])]=df['per_cap_nosp'].values\n",
      "print x4_back_2[1,:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "sparse matrix length is ambiguous; use getnnz() or shape[0]",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-63-b193e2b7ebcf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx4_back_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2034\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx4_back\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mx4_back_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#x_backTF_2[:,:-1] = x_backTF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx4_back_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx4_back\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx4_back_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx4_back\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'per_cap_nosp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/dist-packages/scipy/sparse/base.pyc\u001b[0m in \u001b[0;36m__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;31m# return self.getnnz()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         raise TypeError(\"sparse matrix length is ambiguous; use getnnz()\"\n\u001b[0m\u001b[0;32m    183\u001b[0m                          \" or shape[0]\")\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mTypeError\u001b[0m: sparse matrix length is ambiguous; use getnnz() or shape[0]"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y4 = (df['polarity'] == 0).values.astype(np.int)\n",
      "xtrain4, xtest4, ytrain4, ytest4 = train_test_split(x4_back_2,Y4, test_size=0.5, random_state=41)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"multinomial w/ percent capitalized\"\n",
      "clf_mn_4 = MultinomialNB().fit(xtrain4, ytrain4)\n",
      "accuracy_report(clf_mn_4, xtrain4, ytrain4, xtest4, ytest4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "multinomial w/ percent capitalized\n",
        "Accuracy: 82.30%\n",
        "Accuracy on training data: 0.99\n"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y4 = (df['polarity'] == 0).values.astype(np.int)\n",
      "xtrain4, xtest4, ytrain4, ytest4 = train_test_split(x4_back,Y4, test_size=0.5, random_state=41)\n",
      "print \"multinomial w/o percent capitalized\"\n",
      "clf_mn_4 = MultinomialNB().fit(xtrain4, ytrain4)\n",
      "accuracy_report(clf_mn_4, xtrain4, ytrain4, xtest4, ytest4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "multinomial w/o percent capitalized\n",
        "Accuracy: 82.60%\n",
        "Accuracy on training data: 0.99\n"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#I'm surprised by these results.  Percent capitalized may be simply an ambiguous feature."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Overall none of the models better the performance of the original Count Vectorizer model trained on the \"as they came\" tweets."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now try a logistic regression model.\n",
      "Using the training set with the hash tags removed and the addition of the percent capitalized field."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Simple model without cross validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y4 = (df['polarity'] == 0).values.astype(np.int)\n",
      "xtrain4, xtest4, ytrain4, ytest4 = train_test_split(x4_back_2,Y4, test_size=0.5, random_state=41)\n",
      "reg=1000\n",
      "clf_lr = LogisticRegression(C=reg)\n",
      "clf_lr.fit(xtrain4, ytrain4)\n",
      "accuracy_report(clf_lr, xtrain4, ytrain4, xtest4, ytest4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy: 82.20%\n",
        "Accuracy on training data: 1.00\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.crosstab(Y4, clf_lr.predict(x4_back_2), rownames=[\"Actual\"], colnames=[\"Predicted\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th>Predicted</th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Actual</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 506</td>\n",
        "      <td>  126</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>  55</td>\n",
        "      <td> 1347</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 68,
       "text": [
        "Predicted    0     1\n",
        "Actual              \n",
        "0          506   126\n",
        "1           55  1347"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now add cross validation using the GridSearchCV functionality."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fit_logistic(xtr, ytr, reg=0.0001, pen=\"l2\"):\n",
      "    clf = LogisticRegression(C=reg, penalty=pen)\n",
      "    clf.fit(xtr, ytr)\n",
      "    return clf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cv_optimize(xtr, ytr, paramaterList, pen=\"l2\", n_folds=10):\n",
      "    clf = LogisticRegression(penalty=pen)\n",
      "    parameters = {\"C\": paramaterList}\n",
      "    gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds)\n",
      "    gs.fit(xtr, ytr)\n",
      "    return gs.best_params_, gs.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cv_and_fit(xtr, ytr, parList, pen=\"l2\", nFolds=10):\n",
      "    print \"Penalty is %s\", pen\n",
      "    print \"nFolds is %d\", nFolds\n",
      "    bp, bs = cv_optimize(xtr, ytr, parList, pen, nFolds)\n",
      "    print \"Best Parameter: %s, Best Score: %s\" % (bp, bs)\n",
      "    clf = fit_logistic(xtr, ytr, bp['C'], pen)\n",
      "    return clf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print x4_back_2.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(2034, 23048)\n"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#The reason the accuracy score is so high is because xtr is set to all of x4_back_2\n",
      "\n",
      "nFlds = 5\n",
      "regSpace = np.logspace(-4, 5, num=100)\n",
      "clf_opt=cv_and_fit(xtr = x4_back_2, ytr = Y4, parList = regSpace, nFolds = nFlds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Penalty is %s l2\n",
        "nFolds is %d 5\n",
        "Best Parameter: {'C': 65793.322465756821}, Best Score: 0.839233038348"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y4 = (df['polarity'] == 0).values.astype(np.int)\n",
      "xtrain4, xtest4, ytrain4, ytest4 = train_test_split(x4_back_2,Y4, test_size=0.5, random_state=41)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accuracy_report(clf_opt, xtrain4, ytrain4, xtest4, ytest4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy: 100.00%\n",
        "Accuracy on training data: 1.00\n"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "#Rerunning the model:\n",
      "model = LogisticRegression(C=65793, penalty=\"l2\")\n",
      "xtrain, xtest, ytrain, ytest = train_test_split(x4_back_2,Y4, test_size=0.5, random_state=20)\n",
      "model.fit(xtrain,ytrain)\n",
      "accuracy_report(model, xtrain, ytrain, xtest, ytest)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy: 82.60%\n",
        "Accuracy on training data: 1.00\n"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.crosstab(Y4, clf_opt.predict(x4_back_2), rownames=[\"Actual\"], colnames=[\"Predicted\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th>Predicted</th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Actual</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 632</td>\n",
        "      <td>    0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>   0</td>\n",
        "      <td> 1402</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 95,
       "text": [
        "Predicted    0     1\n",
        "Actual              \n",
        "0          632     0\n",
        "1            0  1402"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I am HIGHLY SUSPICIOUS of this result. \n",
      "This appears to be a clear case of lots of training on all the data, so not seeing the results of testing on a separate test set. Not sure where the problem lies in the above code.\n",
      "I note the Best Score of 0.839 from the Grid Search.\n",
      "It is possible that the two distributions are non-overlapping. The training data is an array with over 23000 columns. So the data is very very sparse in such a high dimensional space.\n",
      "To use this approach with logistic regression and get a robust result would require the reduction in the dimensionality of the array first.\n",
      "I would also want to readjust the training set to equal priors. So for logistic regression it would be important to balance the training set with equal numbers of polarity 0 and polarity 4 tweets."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Below is just some example work I did to understand better how the count vectorizer is working"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Example the letters represent words\n",
      "tf={'Words':[\"Learning\", \"Python is\", \"one crazy person\"]}\n",
      "tf = pd.DataFrame(tf)\n",
      "tf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Words</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>         Learning</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>        Python is</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> one crazy person</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 69,
       "text": [
        "              Words\n",
        "0          Learning\n",
        "1         Python is\n",
        "2  one crazy person"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testV = CountVectorizer(ngram_range=(1,2))\n",
      "testV.fit(tf['Words'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 70,
       "text": [
        "CountVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
        "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
        "        tokenizer=None, vocabulary=None)"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testV.get_feature_names()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 71,
       "text": [
        "[u'crazy',\n",
        " u'crazy person',\n",
        " u'is',\n",
        " u'learning',\n",
        " u'one',\n",
        " u'one crazy',\n",
        " u'person',\n",
        " u'python',\n",
        " u'python is']"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testX = testV.transform(tf['Words'])\n",
      "#testx = testX.toarray()\n",
      "testx = testX\n",
      "print testx"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 3)\t1\n",
        "  (1, 2)\t1\n",
        "  (1, 7)\t1\n",
        "  (1, 8)\t1\n",
        "  (2, 0)\t1\n",
        "  (2, 1)\t1\n",
        "  (2, 4)\t1\n",
        "  (2, 5)\t1\n",
        "  (2, 6)\t1\n"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So first row is text from line 0 - mainly \"Learning\". Learning is unique word appearing 4th in the list of ngrams. So put a row in the matrix at 0,3 for the first word.\n",
      "Second row \"Python is\" generates 3 ngrams, appearing in the ngram list at positions 2, 7, and 8.\n",
      "Third row \"one crazy person\" generate 5 ngrams, appearing in the ngram list at positionis 0, 1, 4, 5, 6.\n",
      "Since there are NO overlapping words in the text so there are no more than a single \"1\" appearing in any one column of the mapping matrix."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tf={'Words':[\"The Learning\", \"The Python\", \"The crazy\",\"The time\"]}\n",
      "tf = pd.DataFrame(tf)\n",
      "tf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testTF=TfidfVectorizer(ngram_range=(1,2))\n",
      "testTF.fit(tf['Words'])\n",
      "print testTF.get_feature_names()\n",
      "testFX = testTF.transform(tf['Words'])\n",
      "#testfx = testFX.toarray()\n",
      "testfx = testFX\n",
      "print testfx"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\"The\" as a single word appears in the fourth column. It is weighted lower than the other ngrams."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#There is real creativity in your analysis.  Wonderful job, Mark!  My one criticism is that the code is bulky and hard to read.\n",
      "#Two things that could help that (besides practice!) is abstracting the repetitive portions in functions/loops\n",
      "#and naming variables w/ human readable names."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}