{
 "metadata": {
  "name": "",
  "signature": "sha256:fdfc031661ee9445b4f6b75e59493e42ec6b96b0ca21ebe1faf5333772b511be"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import sklearn\n",
      "import sklearn.cross_validation as cv\n",
      "import sklearn.grid_search as gs\n",
      "import sklearn.feature_extraction.text as text\n",
      "import sklearn.naive_bayes as nb\n",
      "import matplotlib.pyplot as plt\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('https://raw.githubusercontent.com/TeachingDataScience/data-science-course/forstudentviewing/12_Naive_Bayes/twitter_training/sts_gold_tweet.csv',';')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['percent_capitalized'] = df.tweet.apply(lambda x: sum([float(x[i] == x.upper()[i]) for i in range(len(x))])/len(x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[100:120]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>id</th>\n",
        "      <th>polarity</th>\n",
        "      <th>tweet</th>\n",
        "      <th>percent_capitalized</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>100</th>\n",
        "      <td> 1467971939</td>\n",
        "      <td> 4</td>\n",
        "      <td>           hanging out with biology til 4am woo  !</td>\n",
        "      <td> 0.256410</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101</th>\n",
        "      <td> 1467917300</td>\n",
        "      <td> 4</td>\n",
        "      <td>                  Happy Morning, la toat? lumea!  </td>\n",
        "      <td> 0.343750</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>102</th>\n",
        "      <td> 1548496948</td>\n",
        "      <td> 4</td>\n",
        "      <td> Watching Oprah that I had taped from earlier! ...</td>\n",
        "      <td> 0.276316</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>103</th>\n",
        "      <td> 2067126108</td>\n",
        "      <td> 4</td>\n",
        "      <td> Chrisette Michelle just came on the ipod . she...</td>\n",
        "      <td> 0.254237</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>104</th>\n",
        "      <td> 1968082909</td>\n",
        "      <td> 4</td>\n",
        "      <td>              Lakers! Going to the finals!! Weee! </td>\n",
        "      <td> 0.361111</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>105</th>\n",
        "      <td> 2257073099</td>\n",
        "      <td> 4</td>\n",
        "      <td> Getting my hair cut while texting with my brot...</td>\n",
        "      <td> 0.255814</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>106</th>\n",
        "      <td> 1467990301</td>\n",
        "      <td> 4</td>\n",
        "      <td> @ILUVNKOTB he wants u to follow who he follows...</td>\n",
        "      <td> 0.295455</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>107</th>\n",
        "      <td> 1468006104</td>\n",
        "      <td> 4</td>\n",
        "      <td> @dmf71 rrrrrr you so very sweet a big hi to yo...</td>\n",
        "      <td> 0.381818</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>108</th>\n",
        "      <td> 2192673181</td>\n",
        "      <td> 4</td>\n",
        "      <td> @scrambledeggos Seattle is very nice. So green...</td>\n",
        "      <td> 0.236111</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>109</th>\n",
        "      <td> 2031911307</td>\n",
        "      <td> 4</td>\n",
        "      <td> great song  @Sharpatoulas: &amp;quot;seattle's bes...</td>\n",
        "      <td> 0.329114</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>110</th>\n",
        "      <td> 1751574773</td>\n",
        "      <td> 4</td>\n",
        "      <td> @taylorswift13 Taylor Swift I think you're so ...</td>\n",
        "      <td> 0.262136</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>111</th>\n",
        "      <td> 2066535902</td>\n",
        "      <td> 4</td>\n",
        "      <td>    starbucks &amp;amp; tanning. good start for today </td>\n",
        "      <td> 0.217391</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>112</th>\n",
        "      <td> 1759502287</td>\n",
        "      <td> 4</td>\n",
        "      <td> @Oprah We are so happy to have you back in the...</td>\n",
        "      <td> 0.290000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>113</th>\n",
        "      <td> 1881097261</td>\n",
        "      <td> 4</td>\n",
        "      <td> Not long till LONDON BABY!!!  and then the EMI...</td>\n",
        "      <td> 0.678161</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>114</th>\n",
        "      <td> 1824369536</td>\n",
        "      <td> 4</td>\n",
        "      <td> I got back from Brazil last week, and everyone...</td>\n",
        "      <td> 0.240000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>115</th>\n",
        "      <td> 2011034549</td>\n",
        "      <td> 4</td>\n",
        "      <td>        @MissSydneyJ Im good, lol... I feel awake </td>\n",
        "      <td> 0.404762</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>116</th>\n",
        "      <td> 1967926543</td>\n",
        "      <td> 4</td>\n",
        "      <td> The Lakers got it..  hahaah this is why i love LA</td>\n",
        "      <td> 0.346939</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>117</th>\n",
        "      <td> 1468037411</td>\n",
        "      <td> 4</td>\n",
        "      <td> pierce surprised me w/ 2 koi fish today! he's ...</td>\n",
        "      <td> 0.268116</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>118</th>\n",
        "      <td> 1467953838</td>\n",
        "      <td> 4</td>\n",
        "      <td>           Still up. Playin cards with the girls. </td>\n",
        "      <td> 0.282051</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>119</th>\n",
        "      <td> 2189616175</td>\n",
        "      <td> 4</td>\n",
        "      <td> I have a great fun day with my best friend!! W...</td>\n",
        "      <td> 0.227273</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "             id  polarity                                              tweet  \\\n",
        "100  1467971939         4            hanging out with biology til 4am woo  !   \n",
        "101  1467917300         4                   Happy Morning, la toat? lumea!     \n",
        "102  1548496948         4  Watching Oprah that I had taped from earlier! ...   \n",
        "103  2067126108         4  Chrisette Michelle just came on the ipod . she...   \n",
        "104  1968082909         4               Lakers! Going to the finals!! Weee!    \n",
        "105  2257073099         4  Getting my hair cut while texting with my brot...   \n",
        "106  1467990301         4  @ILUVNKOTB he wants u to follow who he follows...   \n",
        "107  1468006104         4  @dmf71 rrrrrr you so very sweet a big hi to yo...   \n",
        "108  2192673181         4  @scrambledeggos Seattle is very nice. So green...   \n",
        "109  2031911307         4  great song  @Sharpatoulas: &quot;seattle's bes...   \n",
        "110  1751574773         4  @taylorswift13 Taylor Swift I think you're so ...   \n",
        "111  2066535902         4     starbucks &amp; tanning. good start for today    \n",
        "112  1759502287         4  @Oprah We are so happy to have you back in the...   \n",
        "113  1881097261         4  Not long till LONDON BABY!!!  and then the EMI...   \n",
        "114  1824369536         4  I got back from Brazil last week, and everyone...   \n",
        "115  2011034549         4         @MissSydneyJ Im good, lol... I feel awake    \n",
        "116  1967926543         4  The Lakers got it..  hahaah this is why i love LA   \n",
        "117  1468037411         4  pierce surprised me w/ 2 koi fish today! he's ...   \n",
        "118  1467953838         4            Still up. Playin cards with the girls.    \n",
        "119  2189616175         4  I have a great fun day with my best friend!! W...   \n",
        "\n",
        "     percent_capitalized  \n",
        "100             0.256410  \n",
        "101             0.343750  \n",
        "102             0.276316  \n",
        "103             0.254237  \n",
        "104             0.361111  \n",
        "105             0.255814  \n",
        "106             0.295455  \n",
        "107             0.381818  \n",
        "108             0.236111  \n",
        "109             0.329114  \n",
        "110             0.262136  \n",
        "111             0.217391  \n",
        "112             0.290000  \n",
        "113             0.678161  \n",
        "114             0.240000  \n",
        "115             0.404762  \n",
        "116             0.346939  \n",
        "117             0.268116  \n",
        "118             0.282051  \n",
        "119             0.227273  "
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tf = text.TfidfVectorizer()\n",
      "X = tf.fit_transform(df['tweet'])\n",
      "print(X.shape)\n",
      "X[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(2034, 5457)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "<1x5457 sparse matrix of type '<type 'numpy.float64'>'\n",
        "\twith 22 stored elements in Compressed Sparse Row format>"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr = X.toarray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Each sample has ~{0:.2f}% non-zero features.\".format(\n",
      "          100 * X.nnz / float(X.shape[0] * X.shape[1])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Each sample has ~0.24% non-zero features.\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = df['polarity'] #had to add this line - y was missing"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(X_train, X_test,\n",
      " y_train, y_test) = cv.train_test_split(X, y,\n",
      "                                        test_size=.2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "We use a Bernoulli Naive Bayes classifier with a grid search on the parameter \u03b1."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bnb = gs.GridSearchCV(nb.BernoulliNB(), param_grid={'alpha':np.logspace(-2., 2., 50)})\n",
      "bnb.fit(X_train, y_train);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bnb.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "0.82800982800982803"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bnb.best_params_ #best alpha value is 0.24"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "{'alpha': 0.2442053094548651}"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "lets take a look at the 50 words we find in the most polorized twits"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We first get the words corresponding to each feature.\n",
      "names = np.asarray(tf.get_feature_names())\n",
      "# Next, we display the 50 words with the largest\n",
      "# coefficients.\n",
      "print(','.join(names[np.argsort(\n",
      "    bnb.best_estimator_.coef_[0,:])[::-1][:50]]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "to,the,and,you,in,for,my,of,it,on,with,is,love,that,me,good,so,day,taylor,swift,this,have,just,new,are,your,was,we,lakers,can,now,see,all,go,get,from,at,today,great,up,haha,amp,england,going,night,nice,time,what,got,oprah\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#This is condenses and not readable.  Try breaking it into a few steps.\n",
      "top50indices = np.argsort(bnb.best_estimator_.coef_[0,:])[-50:] #in one line this gives us the location of the 50 highest coefficients\n",
      "#note: [::-1] just reverses the order of the list\n",
      "#easier to just select the last 50 from the initial list\n",
      "names[top50indices]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": [
        "array([u'oprah', u'got', u'what', u'time', u'nice', u'night', u'going',\n",
        "       u'england', u'amp', u'haha', u'up', u'great', u'today', u'at',\n",
        "       u'from', u'get', u'go', u'all', u'see', u'now', u'can', u'lakers',\n",
        "       u'we', u'was', u'your', u'are', u'new', u'just', u'have', u'this',\n",
        "       u'swift', u'taylor', u'day', u'so', u'good', u'me', u'that',\n",
        "       u'love', u'is', u'with', u'on', u'it', u'of', u'my', u'for', u'in',\n",
        "       u'you', u'and', u'the', u'to'], \n",
        "      dtype='<U35')"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "and in the least polorized - "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(','.join(names[np.argsort(\n",
      "    bnb.best_estimator_.coef_[0,:])[:50]]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ktjade,miss_kookie,missed,misserble,missin,missing,misssarcastic,missss,missyatwsu,mitchin,mkoenigsberg,mma,mmitchelldaviss,mo,mising,mobile,mochiatta,mocking,modem,modernmod,molested,molester,momma,mommy,moms,mondays,money,moneys,monies,mocha,miserably,mirrors,mirror,michelletripp,michigan,micro,microsoft,mid,middle,mightyxtra,migranes,miguel,miketopia,mikey,mild,miles,military,milk,milkshake,million\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Lets try our model:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(bnb.predict(tf.transform([\n",
      "    \"MODEL GOOD TESTER IS AWESOME!!!!!\",\n",
      "    \"LASSOS IS TERRIBLE!!!!!\",\n",
      "    \"It is a pleasure to open the information Age exhibition today at the science museum and I hope people will enjoy visiting.  Elizabeth R\",\n",
      "    \"Thunder storms are approaching\",\n",
      "    \"Explosion in white house POTUS injured\",\n",
      "    \"sometimes I get really happy over fonts\",\n",
      "    \"kanye west sometimes I get really happy over fonts\"\n",
      "    ])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[4 0 4 0 0 0 4]\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#Good job Ari getting your hands dirty with gridsearch and the more detailed vectorizer function.  I would\n",
      "#have liked to see you test a second model or validate the one you had."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}